{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa50cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix, matthews_corrcoef\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import BatchNormalization, Flatten, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71aa0762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('8taijiquan.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1e867e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check the data info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591cb26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove missing values\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de113fd9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check the null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81339763",
   "metadata": {},
   "source": [
    "## Calculate Angle Keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f602fee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angle(frame, keypoint_1, keypoint_2, keypoint_3, keypoint_4):\n",
    "    a = np.array([frame['x' + str(keypoint_1)], frame['y' + str(keypoint_1)]])\n",
    "    b = np.array([frame['x' + str(keypoint_2)], frame['y' + str(keypoint_2)]])\n",
    "    c = np.array([frame['x' + str(keypoint_3)], frame['y' + str(keypoint_3)]])\n",
    "    d = np.array([frame['x' + str(keypoint_4)], frame['y' + str(keypoint_4)]])\n",
    "    \n",
    "    ba = a - b\n",
    "    bc = c - b\n",
    "    cd = d - c\n",
    "    \n",
    "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "    angle = math.degrees(np.arccos(cosine_angle))\n",
    "    \n",
    "    if angle > 180.0:\n",
    "        angle = 360 - angle\n",
    "        \n",
    "    return angle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39828a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['angle1'] = df.apply(lambda row: get_angle(row, 11, 13, 23, 24), axis = 1)\n",
    "df['angle2'] = df.apply(lambda row: get_angle(row, 25, 26, 27, 28), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ecc964",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46537ec4",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8235dd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataset to a CSV file\n",
    "df.to_csv('taijiquan_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1da44df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('taijiquan_dataset.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efeab4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are any missing values in the dataset\n",
    "missing_values = dataset.isnull().sum()\n",
    "print(\"Missing Values:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aba33a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing values\n",
    "dataset.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d82af2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the color pallete to 'pastel'\n",
    "sns.set_palette('pastel')\n",
    "\n",
    "# Create the histogram plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(dataset['class'], bins=20, kde=True)\n",
    "\n",
    "plt.xlabel('Angle 1', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "plt.title('Distribution of Taijiquan', fontsize=16)\n",
    "\n",
    "# Annotate each bin with the number of data points\n",
    "for p in plt.gca().patches:\n",
    "    plt.gca().text(p.get_x() + p.get_width() / 2., p.get_height(), f'{int(p.get_height())}',\n",
    "                ha='center', va='bottom', fontsize=12, color='black')\n",
    "\n",
    "# Customize the style\n",
    "sns.set_style(\"whitegrid\")  # Use a white grid background\n",
    "sns.despine()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fc4e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset loaded as 'dataset'\n",
    "labels_count = dataset['class'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(12, 6)) # Set the figure size\n",
    "\n",
    "# Create a bar chart\n",
    "plt.bar(labels_count.index, labels_count.values, color='skyblue')\n",
    "\n",
    "plt.xlabel('Stance', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.title('Stance Distribution', fontsize=16)\n",
    "\n",
    "# Rotate the x-axis labels for better readability\n",
    "plt.xticks(rotation=45, fontsize=12)\n",
    "\n",
    "# Annotate each bar with its count\n",
    "for x, y in zip(labels_count.index, labels_count.values):\n",
    "    plt.text(x, y, str(y), ha='center', va='bottom', fontsize=12, color='black')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790053dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Splitting\n",
    "features = dataset.iloc[:, 1:-2]  # Exclude 'label', 'angle1', and 'angle2' columns\n",
    "labels = dataset['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a16b39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75afe6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7adf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db13a6d5",
   "metadata": {},
   "source": [
    "### Data Splitting: 11,220\n",
    "X_train and y_train_encoded to train your machine learning model, and X_test and y_test_encoded to evaluate the model's performance on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3e9949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform train-test split\n",
    "X_train, X_test, y_train_encoded, y_test_encoded = train_test_split(features, labels_encoded, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6beb6d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31229828",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Size of X_train:\", X_train.shape)\n",
    "print(\"Size of X_test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a65f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Size of y_train_encoded:\", y_train_encoded.shape)\n",
    "print(\"Size of y_test_encoded:\", y_test_encoded.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5058af8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981f7e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(np.unique(labels_encoded))\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fecd5c7",
   "metadata": {},
   "source": [
    "### Feedforward Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0d6390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a feedforward neural network model\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.InputLayer(input_shape=(X_train.shape[1],)))\n",
    "model.add(layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(layers.Dropout(0.7))\n",
    "model.add(layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(layers.Dropout(0.7))\n",
    "model.add(layers.Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "optimizer = Adam(learning_rate=0.001)  # Adjust the learning rate as needed\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5121b8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with different optimizer and learning rate schedule\n",
    "initial_learning_rate = 0.001\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=10000, decay_rate=0.9)\n",
    "optimizer = keras.optimizers.RMSprop(learning_rate=lr_schedule)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9586819f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train_scaled, y_train_encoded, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88db848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test_encoded)\n",
    "print(f'Test accuracy: {test_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdaf4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract training history and plot\n",
    "training_loss = history.history['loss']\n",
    "training_accuracy = history.history['accuracy']\n",
    "validation_loss = history.history['val_loss']\n",
    "validation_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test_encoded)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, len(training_loss) + 1), training_loss, label='Training Loss')\n",
    "plt.plot(range(1, len(validation_loss) + 1), validation_loss, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, len(training_accuracy) + 1), training_accuracy, label='Training Accuracy')\n",
    "plt.plot(range(1, len(validation_accuracy) + 1), validation_accuracy, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4765b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6adb399",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_probabilities = model.predict(X_test_scaled)\n",
    "y_pred_classes = np.argmax(y_pred_probabilities, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred_classes)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Calculate precision, recall, and F1-score\n",
    "precision = precision_score(y_test_encoded, y_pred_classes, average='weighted')\n",
    "recall = recall_score(y_test_encoded, y_pred_classes, average='weighted')\n",
    "f1 = f1_score(y_test_encoded, y_pred_classes, average='weighted')\n",
    "\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "\n",
    "# Display a classification report\n",
    "class_names = label_encoder.classes_\n",
    "report = classification_report(y_test_encoded, y_pred_classes, target_names=class_names, zero_division=0)\n",
    "print('Classification Report:')\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd642156",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "confusion = confusion_matrix(y_test_encoded, y_pred_classes)\n",
    "\n",
    "# Define class names for the target labels (change as needed)\n",
    "class_names = [\"Bow-Arrow\", \"False Stance\", \"Four-Six\", \"Golden Rooster\", \"Horse Stance\", \"Sitting\", \"Taijiquan\", \"Tame\"]\n",
    "\n",
    "# Create a Seaborn heatmap for the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion, annot=True, fmt='d', cmap='YlGnBu', cbar=True,\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "# Display the confusion matrix\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5796d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCC = (TP * TN - FP * FN) / sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef\n",
    "\n",
    "mcc = matthews_corrcoef(y_test_encoded, y_pred_classes)\n",
    "print(\"MCC:\", mcc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4bc039",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "# Define the number of folds (e.g., k = 10 for 10-fold cross-validation)\n",
    "k = 10\n",
    "\n",
    "# Initialize lists to store accuracy results for each fold\n",
    "accuracy_per_fold = []\n",
    "\n",
    "# Create a KFold object\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# Iterate over the folds\n",
    "for train_index, val_index in kf.split(X_train_scaled):\n",
    "    # Split the data into training and validation sets for this fold\n",
    "    X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
    "    y_train_fold, y_val_fold = y_train_encoded[train_index], y_train_encoded[val_index]\n",
    "\n",
    "    num_classes = len(np.unique(y_train_encoded))\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=(X_train.shape[1],)))\n",
    "    model.add(keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Dropout(0.7))\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Dropout(0.7))\n",
    "    model.add(keras.layers.Dense(32, activation='relu'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "    # Compile the model for this fold\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model on the current fold\n",
    "    history = model.fit(X_train_fold, y_train_fold, epochs=100, batch_size=32, validation_data=(X_val_fold, y_val_fold), verbose=0)\n",
    "\n",
    "    # Evaluate the model on the validation set for this fold\n",
    "    val_loss, val_accuracy = model.evaluate(X_val_fold, y_val_fold)\n",
    "    accuracy_per_fold.append(val_accuracy)\n",
    "\n",
    "# Calculate and print the average accuracy across all folds\n",
    "average_accuracy = sum(accuracy_per_fold) / k\n",
    "print(f'Average Accuracy: {average_accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a396d88f",
   "metadata": {},
   "source": [
    "### Percentage of Keypoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2412820",
   "metadata": {},
   "source": [
    "# X_train, X_test, y_train_encoded, y_test_encoded = train_test_split(features, labels_encoded, test_size=0.2, random_state=42)\n",
    "The variables X_test and y_test_encoded contain the test data, and y_test_encoded specifically contains the ground truth labels for your test data. So, you can consider y_test_encoded as your ground truth data for your test set. You can use X_test for the input features and y_test_encoded for the ground truth to calculate accuracy or any other evaluation metrics for your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b33d532",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a function to calculate accuracy for a single keypoint\n",
    "def calculate_keypoint_accuracy(predicted_keypoint, ground_truth_keypoint, threshold):\n",
    "    distance = np.linalg.norm(np.array(predicted_keypoint) - np.array(ground_truth_keypoint))\n",
    "    return int(distance < threshold)\n",
    "\n",
    "# Define a function to calculate accuracy for all 33 landmarks\n",
    "def calculate_overall_accuracy(predicted_landmarks, ground_truth_landmarks, threshold):\n",
    "    num_landmarks = len(predicted_landmarks)\n",
    "    accuracies = [calculate_keypoint_accuracy(predicted_landmarks[i], ground_truth_landmarks[i], threshold) for i in range(num_landmarks)]\n",
    "    percentage_accurate = sum(accuracies) / num_landmarks * 100\n",
    "    return percentage_accurate\n",
    "\n",
    "# Usage\n",
    "threshold = 0.5  # Define your accuracy threshold\n",
    "predicted_landmarks = y_pred_classes  # List of predicted landmarks (each landmark is [x, y])\n",
    "ground_truth_landmarks = y_test_encoded     # List of ground truth landmarks (each landmark is [x, y])\n",
    "\n",
    "accuracy = calculate_overall_accuracy(predicted_landmarks, ground_truth_landmarks, threshold)\n",
    "print(f\"Overall Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3693b462",
   "metadata": {},
   "source": [
    "# Model Save\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ec4372",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Save the model architecture to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "# Save the model weights to HDF5\n",
    "model.save_weights(\"model_weights.h5\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbaa829",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from keras.models import model_from_json\n",
    "\n",
    "# Load the model architecture from JSON\n",
    "with open('model.json', 'r') as json_file:\n",
    "    loaded_model_json = json_file.read()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# Load the model weights from HDF5\n",
    "loaded_model.load_weights(\"model_weights.h5\")\n",
    "\n",
    "# Compile the loaded model \n",
    "loaded_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a356b689",
   "metadata": {},
   "source": [
    "### Statistical Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5231dbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Data Preparation\n",
    "dataset['label'] = pd.Categorical(dataset['label'])\n",
    "\n",
    "# Perform the One-Way ANOVA\n",
    "model = ols('angle1 ~ label', data=dataset).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Post Hoc Analysis (Turkey's HSD Test)\n",
    "tukey = pairwise_tukeyhsd(endog=dataset['angle1'], groups=dataset['label'], alpha=0.05)\n",
    "print(tukey.summary())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c08ed8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
