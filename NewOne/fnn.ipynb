{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('8taijiquan.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique values in the 'class' column\n",
    "unique_classes = df['class'].unique()\n",
    "\n",
    "# Display the unique values\n",
    "print(\"Unique Classes:\", unique_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of classes\n",
    "print(df['class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['class']=='Horse Stance']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the color palette to 'pastel'\n",
    "sns.set_palette('pastel')\n",
    "\n",
    "# Create the histogram plot\n",
    "plt.figure(figsize=(14, 6))  # Adjust the figure size as needed\n",
    "sns.histplot(df['class'], bins=20, kde=True)\n",
    "\n",
    "plt.xlabel('Stance', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "plt.title('Distribution of Taijiquan', fontsize=16)\n",
    "\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "for p in plt.gca().patches:\n",
    "    plt.gca().text(p.get_x() + p.get_width() / 2., p.get_height(), f'{int(p.get_height())}',\n",
    "                ha='center', va='bottom', fontsize=12, color='black')\n",
    "\n",
    "sns.set_style(\"whitegrid\")  \n",
    "sns.despine()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Training, validation, and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training, validation, and testing sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    df.drop('class', axis=1),  # Features (X)\n",
    "    df['class'],                # Target variable (y)\n",
    "    test_size=0.3,              # Percentage of data for the validation set\n",
    "    random_state=42,            # Random state\n",
    "    stratify=df['class']         # Class distribution in the splits\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp,                     # Features (X) after the first split\n",
    "    y_temp,                     # Target variable (y) after the first split\n",
    "    test_size=0.5,              # Percentage of data for the test set (relative to X_temp)\n",
    "    random_state=42,            # Random state\n",
    "    stratify=y_temp              # Class distribution in the splits\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Landmark-based Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply landmark-based augmentation\n",
    "def apply_landmark_augmentation(landmarks, angle_range=(-10, 10), scale_range=(0.9, 1.1)):\n",
    "    augmented_landmarks = landmarks.copy()\n",
    "    num_landmarks = landmarks.shape[0]\n",
    "\n",
    "    # Apply augmentation to each landmark\n",
    "    for i in range(num_landmarks):\n",
    "        angle = np.random.uniform(angle_range[0], angle_range[1])\n",
    "        rotation_matrix = np.array([[np.cos(np.radians(angle)), -np.sin(np.radians(angle))],\n",
    "                                    [np.sin(np.radians(angle)), np.cos(np.radians(angle))]])\n",
    "        augmented_landmarks[i, :2] = np.dot(augmented_landmarks[i, :2], rotation_matrix.T)\n",
    "        scale_factor = np.random.uniform(scale_range[0], scale_range[1])\n",
    "        augmented_landmarks[i, :2] *= scale_factor\n",
    "\n",
    "    return augmented_landmarks.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply landmark-based augmentation to X_train\n",
    "X_train_augmented = []\n",
    "for index, row in X_train.iterrows():\n",
    "    landmarks = np.array(row).reshape(-1, 4)  \n",
    "    augmented_landmarks = apply_landmark_augmentation(landmarks)\n",
    "    X_train_augmented.append(augmented_landmarks)\n",
    "\n",
    "X_train_augmented = pd.DataFrame(X_train_augmented, columns=X_train.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode class labels to numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_val_encoded = label_encoder.transform(y_val)\n",
    "y_test_encoded = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the FNN model with modifications\n",
    "def create_fnn_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.0001), input_shape=input_shape))\n",
    "    model.add(Dropout(0.5))  # Adjust dropout rate\n",
    "    model.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.0001)))\n",
    "    model.add(Dropout(0.5))  # Adjust dropout rate\n",
    "    model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "\n",
    "    optimizer = Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create and train the FNN model with early stopping\n",
    "input_shape_fnn = (X_train_augmented.shape[1],)\n",
    "fnn_model = create_fnn_model(input_shape_fnn)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "fnn_history = fnn_model.fit(X_train_augmented, y_train_encoded, epochs=20, batch_size=32, validation_data=(X_val, y_val_encoded), callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fnn_history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(fnn_history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the FNN model on the test set\n",
    "test_loss_fnn, test_accuracy_fnn = fnn_model.evaluate(X_test, y_test_encoded)\n",
    "print(f'Test Accuracy (FNN): {test_accuracy_fnn}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix for FNN\n",
    "y_pred_fnn = fnn_model.predict(X_test)\n",
    "y_pred_classes_fnn = np.argmax(y_pred_fnn, axis=1)\n",
    "conf_matrix_fnn = confusion_matrix(y_test_encoded, y_pred_classes_fnn)\n",
    "print(conf_matrix_fnn)\n",
    "sns.heatmap(conf_matrix_fnn, annot=True, fmt='d', cmap='Blues', cbar=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix (FNN)')\n",
    "plt.show()\n",
    "\n",
    "# Classification Report for FNN\n",
    "class_report_fnn = classification_report(y_test_encoded, y_pred_classes_fnn)\n",
    "print('Classification Report (FNN):')\n",
    "print(class_report_fnn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold Cross Validation\n",
    "X_train_augmented = np.array(X_train_augmented)\n",
    "y_train_encoded = np.array(y_train_encoded)\n",
    "\n",
    "# Define the number of folds\n",
    "n_splits = 5  \n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store results for each fold\n",
    "all_train_accuracy = []\n",
    "all_val_accuracy = []\n",
    "\n",
    "# Loop through the folds\n",
    "for fold_num, (train_index, val_index) in enumerate(kf.split(X_train_augmented, y_train_encoded), 1):\n",
    "    X_train_fold, X_val_fold = X_train_augmented[train_index], X_train_augmented[val_index]\n",
    "    y_train_fold, y_val_fold = y_train_encoded[train_index], y_train_encoded[val_index]\n",
    "\n",
    "    # Create and train the FNN model for each fold\n",
    "    fnn_model = create_fnn_model(input_shape_fnn)\n",
    "    history = fnn_model.fit(\n",
    "        X_train_fold, y_train_fold,\n",
    "        epochs=20, batch_size=32,\n",
    "        validation_data=(X_val_fold, y_val_fold),\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "\n",
    "    # Evaluate the model on the training and validation data for each fold\n",
    "    _, train_accuracy = fnn_model.evaluate(X_train_fold, y_train_fold, verbose=0)\n",
    "    _, val_accuracy = fnn_model.evaluate(X_val_fold, y_val_fold, verbose=0)\n",
    "\n",
    "    print(f\"Fold {fold_num}: Training Accuracy = {train_accuracy:.4f}, Validation Accuracy = {val_accuracy:.4f}\")\n",
    "\n",
    "    # Store the training and validation accuracy for each fold\n",
    "    all_train_accuracy.append(train_accuracy)\n",
    "    all_val_accuracy.append(val_accuracy)\n",
    "\n",
    "# Calculate the average training and validation accuracy over all folds\n",
    "avg_train_accuracy = np.mean(all_train_accuracy)\n",
    "avg_val_accuracy = np.mean(all_val_accuracy)\n",
    "\n",
    "print(f\"\\nAverage Training Accuracy Across Folds = {avg_train_accuracy:.4f}\")\n",
    "print(f\"Average Validation Accuracy Across Folds = {avg_val_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentage of Keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a function to calculate accuracy for a single keypoint\n",
    "def calculate_keypoint_accuracy(predicted_keypoint, ground_truth_keypoint, threshold):\n",
    "    distance = np.linalg.norm(np.array(predicted_keypoint) - np.array(ground_truth_keypoint))\n",
    "    return int(distance < threshold)\n",
    "\n",
    "# Define a function to calculate accuracy for all 33 landmarks\n",
    "def calculate_overall_accuracy(predicted_landmarks, ground_truth_landmarks, threshold):\n",
    "    num_landmarks = len(predicted_landmarks)\n",
    "    accuracies = [calculate_keypoint_accuracy(predicted_landmarks[i], ground_truth_landmarks[i], threshold) for i in range(num_landmarks)]\n",
    "    percentage_accurate = sum(accuracies) / num_landmarks * 100\n",
    "    return percentage_accurate\n",
    "\n",
    "# Usage\n",
    "threshold = 0.5  # Define your accuracy threshold\n",
    "predicted_landmarks = y_pred_classes_fnn  \n",
    "ground_truth_landmarks = y_test_encoded    \n",
    "\n",
    "accuracy = calculate_overall_accuracy(predicted_landmarks, ground_truth_landmarks, threshold)\n",
    "print(f\"Overall Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Combine the training and validation accuracies for each fold into a list of arrays\n",
    "all_accuracies = [np.array([all_train_accuracy[i], all_val_accuracy[i]]) for i in range(n_splits)]\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "statistic, p_value = f_oneway(*all_accuracies)\n",
    "\n",
    "# Print the results\n",
    "print(f'ANOVA Statistic: {statistic}')\n",
    "print(f'P-value: {p_value}')\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05  # Significance level\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis. There are significant differences between at least two group means.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis. There is no significant difference between group means.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment and Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the trained FNN model\n",
    "fnn_model.save('saved_model/fnn_model')\n",
    "\n",
    "# Save the label encoder for later use\n",
    "with open('saved_model/label_encoder.pkl', 'wb') as le_file:\n",
    "    pickle.dump(label_encoder, le_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "loaded_model = tf.keras.models.load_model('saved_model/fnn_model')\n",
    "\n",
    "# Load the label encoder\n",
    "with open('saved_model/label_encoder.pkl', 'rb') as le_file:\n",
    "    loaded_label_encoder = pickle.load(le_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Initialize BlazePose\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose(\n",
    "    min_detection_confidence=0.6,\n",
    "    min_tracking_confidence=0.6\n",
    ")\n",
    "\n",
    "# Start capturing video from the camera\n",
    "cap = cv2.VideoCapture(1)  # 0 for the default camera, adjust if necessary\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1200)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 500)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to RGB\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the frame with BlazePose\n",
    "    results = pose.process(frame_rgb)\n",
    "\n",
    "    # Recolor image back to BGR for rendering\n",
    "    frame = cv2.cvtColor(frame_rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Detect Taijiquan Stances (class)\n",
    "    if results.pose_landmarks:\n",
    "        # Extract Pose landmarks\n",
    "        pose_landmarks = results.pose_landmarks.landmark\n",
    "        pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose_landmarks]).flatten())\n",
    "\n",
    "        # Make Detections\n",
    "        X = pd.DataFrame([pose_row])\n",
    "\n",
    "        # Convert X to numpy array\n",
    "        input_data = X.to_numpy().astype(np.float32)\n",
    "\n",
    "        # Make predictions using the Keras model\n",
    "        predictions = loaded_model.predict(input_data)\n",
    "        body_language_class = np.argmax(predictions)\n",
    "        body_language_prob = predictions[0]\n",
    "\n",
    "        print(body_language_class, body_language_prob)\n",
    "\n",
    "        # Display Probability\n",
    "        cv2.putText(frame, 'PROB', (15, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(frame, str(round(body_language_prob[body_language_class], 2)),\n",
    "                    (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "        # Display detected class\n",
    "        cv2.putText(frame, f'CLASS: {loaded_label_encoder.classes_[body_language_class]}', (10, 90),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "        # Draw pose landmarks\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame,\n",
    "            results.pose_landmarks,\n",
    "            mp_pose.POSE_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=4),\n",
    "            mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "        )\n",
    "\n",
    "    cv2.imshow('Pose Detection', frame)\n",
    "\n",
    "    # Check for exit key (q)\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BlazePose\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose(\n",
    "    min_detection_confidence=0.6,\n",
    "    min_tracking_confidence=0.6\n",
    ")\n",
    "\n",
    "# Start capturing video from the camera\n",
    "cap = cv2.VideoCapture(0)  # 0 for the default camera, adjust if necessary\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1200)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 800)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to RGB\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the frame with BlazePose\n",
    "    results = pose.process(frame_rgb)\n",
    "\n",
    "    # Recolor image back to BGR for rendering\n",
    "    frame = cv2.cvtColor(frame_rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Detect Taijiquan Stances (class)\n",
    "    if results.pose_landmarks:\n",
    "        # Extract Pose landmarks\n",
    "        pose_landmarks = results.pose_landmarks.landmark\n",
    "        pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose_landmarks]).flatten())\n",
    "\n",
    "        # Make Detections\n",
    "        X = pd.DataFrame([pose_row])\n",
    "\n",
    "        # Convert X to numpy array\n",
    "        input_data = X.to_numpy().astype(np.float32)\n",
    "\n",
    "        # Run inference using the loaded FNN model\n",
    "        # Make predictions using the Keras model\n",
    "        predictions = loaded_model.predict(input_data)\n",
    "        body_language_class = np.argmax(predictions)\n",
    "        body_language_prob = predictions[0]\n",
    "\n",
    "        print(body_language_class, body_language_prob)\n",
    "\n",
    "        # Convert landmark coordinates to integers\n",
    "        landmarks_as_pixels = np.array([(int(landmark.x * frame.shape[1]), int(landmark.y * frame.shape[0])) for landmark in results.pose_landmarks.landmark])\n",
    "\n",
    "        # Calculate bounding rectangle\n",
    "        bbox_c = cv2.boundingRect(landmarks_as_pixels)\n",
    "\n",
    "        # Draw the bounding box\n",
    "        cv2.rectangle(frame, (int(bbox_c[0]), int(bbox_c[1])), (int(bbox_c[0] + bbox_c[2]), int(bbox_c[1] + bbox_c[3])), (0, 255, 0), 2)\n",
    "\n",
    "        # Display Probability\n",
    "        cv2.putText(frame, 'PROB', (15, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        cv2.putText(frame, str(round(body_language_prob[0, body_language_class], 2)),\n",
    "                    (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Display detected class\n",
    "        cv2.putText(frame, f'CLASS: {body_language_class}', (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Draw pose landmarks\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame,\n",
    "            results.pose_landmarks,\n",
    "            mp_pose.POSE_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=4),\n",
    "            mp_drawing.DrawingSpec(color=(0, 191, 255), thickness=2, circle_radius=2)\n",
    "        )\n",
    "\n",
    "        # Add class label on the bounding box\n",
    "        cv2.putText(frame, f'CLASS: {body_language_class}', (int(bbox_c[0]), int(bbox_c[1]) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow('Pose Detection', frame)\n",
    "\n",
    "    # Check for exit key (q)\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
